Roteiro Apresentacao (uso pessoal)
- Objetivo/visao: fila distribuida com lider, eleicao Bully, exclusao mutua Ricart-Agrawala, relogio logico Lamport, sincronismo fisico Cristian, replicacao via 2PC, roteamento/caixa de correio e retries TCP (arquivos-chave: src/node/node.py, src/algorithms/*.py, src/common/*.py).
- Topologia e transporte: nos TCP asyncio trocando envelopes JSON (src/common/messages.py); retries com backoff em src/node/transport.py; persistencia em disco data/tasks_<id>.json.
- Algoritmos:
  - Bully: ID maior vence; timeouts disparam auto-eleicao (src/algorithms/bully.py).
  - Lamport: incrementa/atualiza em cada mensagem (src/common/lamport_clock.py).
  - Ricart-Agrawala: REQUEST/REPLY/RELEASE para secao critica de fila/2PC (src/algorithms/ricart_agrawala.py).
  - Cristian: seguidores pedem TIME_REQUEST ao lider para offset local (src/node/node.py:_time_sync_loop).
- Replicacao e consistencia: 2PC no lider antes do ACK ao cliente (_on_enqueue, _two_phase_replicate, _on_repl_prepare/commit/abort em src/node/node.py); quorum = maioria; prepared expira se nao houver commit; re-sync de seguidores via SYNC_REQUEST/STATE apos perda de mensagens.
- Entrega e confiabilidade:
  - Dequeue marca owner e agenda requeue se faltar ACK (_on_dequeue, _requeue_task).
  - Roteamento P2P com TTL e mailbox para entrega indireta (_on_route, _on_mailbox_push, _deliver_mailbox).
  - Heartbeat + monitor para detectar lider ausente e iniciar Bully; seguidores limpam prepares ao trocar lider (src/node/state.py:set_leader).
- Clientes e interface: produtor src/clients/enqueue_client.py envia ENQUEUE/aguarda ENQUEUE_ACK; consumidor src/clients/worker_client.py recebe TASK e envia TASK_ACK; ambos suportam peers seeds para tolerar troca de lider.
- Script e configuracao: run-local.ps1 -Nodes 3 orquestra cluster local; NodeConfig/PeerConfig em src/common/config.py.
- Testes relevantes (dizer que ja existem e o que cobrem):
  - tests/integration/test_distributed_system.py: eleicao + replicacao 2PC + quorum; sync de follower que retorna; reentrega sem ACK.
  - tests/unit/test_lamport_clock.py, tests/unit/test_algorithms.py, tests/unit/test_node_state.py cobrem componentes de base.
- Benchmark: python scripts/bench.py --messages 60 --concurrency 15 gera throughput/latencia; numeros atuais no README.md (14 msg/s ~0.9s avg no cenario 60x15).

Preparacao rapida
- Opcional limpar estado: Remove-Item data\tasks_*.json -Force
- Se PowerShell bloquear: Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
- Ver PIDs dos nos: Get-NetTCPConnection -LocalPort 8000,8001,8002 | Select LocalPort,OwningProcess

Demonstracao passo a passo (fazer ao vivo)
  1) Subir cluster: .\run-local.ps1 -Nodes 3 (mostrar portas/IDs nos logs Rich).
  2) Enfileirar: python -m src.clients.enqueue_client --id 9000 --payload "hello world" (mostrar ACK).
  3) Consumir: python -m src.clients.worker_client --id 9001 (mostrar payload e ACK enviado).

----- MENSAGENS ----

  4) Falha de lider: derrubar processo com maior ID; aguardar Bully (logs LEADER_ANNOUNCE/leader_timeout) e repetir enqueue/dequeue.
      - Ver PID do lider (porta 8002): Get-NetTCPConnection -LocalPort 8002 | Select OwningProcess
      - Matar lider: Stop-Process -Id <PID> -Force
      - Subir no 3 manualmente: python -m src.node.main --id 3 --host 127.0.0.1 --port 8002 --peers 127.0.0.1:8000:1,127.0.0.1:8001:2
      - Se WinError 52 persistir, usar IPs loopback distintos (ex: no1 127.0.0.2, no2 127.0.0.3, no3 127.0.0.4) e ajustar peers

  5) Persistencia: parar nos, abrir data/tasks_<id>.json e mostrar tarefas/owners/acked. Subir novamente (.\run-local.ps1 -Nodes 3) e mostrar log tasks_recovered.
  6) Reentrega: rodar dequeue mas nao enviar ACK (Ctrl+C antes do ACK); esperar timeout e mostrar requeue em logs. Rodar worker de novo e mostrar mesma task entregue.
  7) Sincronismo fisico: comentar logs time_sync offset_ms=... em seguidores.
  8) Roteamento/mailbox: iniciar produtor apontando para seguidor enquanto lider esta fora; mostrar entrega apos lider voltar (MAILBOX_DELIVER).
  9) Ricart-Agrawala (mutex) no PowerShell: rodar produtores concorrentes
      - janela 1: for ($i=1; $i -le 5; $i++) { python -m src.clients.enqueue_client --id 9100 --payload "p1-$i" }
      - janela 2: for ($i=1; $i -le 5; $i++) { python -m src.clients.enqueue_client --id 9101 --payload "p2-$i" }
      - observar no lider logs REQUEST_CS/REPLY_CS/RELEASE_CS

Extras (opcional)
- Bench rapido: python scripts/bench.py --messages 10 --concurrency 3 (mostra throughput/latencia).
- Ver estado rapido: Get-Content data\tasks_1.json (trocar ID conforme no).

Slides/gancho de fala (ordem): problema -> arquitetura/algoritmos -> fluxo ENQUEUE->2PC->ACK -> tolerancia a falhas (eleicao, quorum, reentrega, sync) -> demonstracao -> resultados de benchmark -> limitacoes (pode perder commit se quorum cai no meio do 2PC; estado em JSON simples; sem autenticacao).
